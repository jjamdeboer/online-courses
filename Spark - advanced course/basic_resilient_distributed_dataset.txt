RESILIENT DISTRIBUTED DATASET (RDD) IS MADE UP OF MULTIPLE PARTITIONS, DETERMINED BY NUMBER OF CPU'S IN THE CLUSTER
PARTITION HAS SEQUENCE OF RECORDS ONE WHICH THE TASK WILL BE EXECUTED
AN RDD IS PART OF A GRAPH/LINEAGE, THAT TRACES ITS HISTORY

SPARK USES STANDARD HADOOP API FOR INPUT, SO THAT IT CAN READ FROM DIFFERENT DATA STORES NEXT TO HDFS, SUCH AS: LOCAL FILE SYSTEM, CLOUDANT, AWS, GOOGLE, AZURE
IT CAN ALSO CONNECT TO HBASE, CASSANDRA, MONGODB

THE PARTITIONS IN THE RDD MAP TO THE HADOOP SPLITS AS DEFINED BY THE INPUTFORMAT; THEREFORE THERE IS DATA LOCALITY WHEN THE SPARK NODES ARE DEPLOYED ON THE HADOOP DATA NODES
THE ROOT RDD DESCRIBES THE ORIGINAL PARTITIONING, THESE ARE INHERITED BY THE CHILD RDD'S
THE TRANSFORMATION RDD ARE EXECUTED ON EACH PARTITION OF THE PARENT RDD
RDD OPERATIONS DO GENERALLY NOT ALTER PARTITIONING, BUT SOMETIMES THEY DO

PARTITIONING HAS A BIG INFLUENCE ON THE PERFORMANCE: EVEN DISTRIBUTION HELPS (GIVEN LIKE NODES); IN HADOOP OR CASSANDRA IT IS ESSENTIAL THAT CORES LINE UP WITH LOGICAL PARTITIONS; THE NUMBER OF PARTITIONS SHOULD CORRELATE TO THE NUMBER OF CPU/NODES IN THE CLUSTER; AVOID SHUFFLING OPERATIONS - A BIG DIFFERENCE WITH HADOOP! - SINCE SHUFFLING IS COSTLY
PARTITIONING IS RELATED TO PARALLELLISM OF TASKS
BALANCE THE PARTITIONS WITH NUMBER OF CORES IN THE CLUSTER
COALESCE CAN DECREASE PARTITIONS WITHOUT A SHUFFLE, BUT PARALLELLISM IS LOST

IT IS POSSIBLE TO KEY EACH VALUE IN A NODE BY 'MAP' OR 'KEYBY'; PARTITIONS ARE NOT CHANGED
SOMETIMES IDENTICAL KEYS ARE NOT CO-LOCATED, HOWEVER, SOMETIMES THIS IS BENEFICIAL; TO ENSURE THE KEY-VALUES ARE CO-LOCATED A HASHPARTITIONER (ALL KEYS WITH THE SAME HASH/IDENTICAL KEYS WILL BE IN THE SAME PARTITION) OR RANGEPARTITIONER CAN BE USED
HASHPARTITIONER DOES NOT GIVE EACH KEY A SEPARATE NODE, FOR THIS, USE CONSISTENT HASHING

RDD'S DESCRIBE A LINEAGE OF TRANSFORMATIONS THAT ARE LAZILY EXECUTED
KEEPING LINEAGE ALLOWS FOR KEEPING THE RESULT IN EVENT OF FAILURE
PERSISTING AN RDD: MAKING IT 'FIXED'/MOVING IT TO MEMORY
IN CASE OF FAILURE, THE LINEAGE MUST BE TRACED BACK TO A ROOT RDD OR A PERSISTED RDD AN REDO THE OPERATIONS

SPARK ACTIONS HAVE THREE STAGES:
JOB: SEQUENCE OF TRANSFORMATIONS INITIATED BY AN ACTION; CONSISTS OF STAGES WHICH CONSISTS OF SMALLER TASKS STILL; TASKS ARE SERIALIZES AND GIVEN TO EXECUTORS
DAG SCHEDULER ANALYZES RDD TO GENERATE STAGES AND TASKS
STAGE BOUNDARIES/STAGES ARE DEFINED BY SHUFFLES/REPARTIONING
TRANSFORMATIONS THAT CAUSE SHUFFLES ARE WIDE DEPENDENCIES
TASKS ARE THE OPERATIONS DEFINED IN THE DRIVER PROGRAM FOR THAT RDD
CLOSURES/LAMBDAS ARE SERIALIZED AND GIVEN TO EACH EXECUTOR WITH A PARTITION ON WHICH THAT FUNCTION MUST BE EXECUTED
TASKS MUST BE SERIALIZABLE IN ORDER TO BE SENT OVER A DISTRIBUTED NETWORK; ALSO REFERENCES THEY MAKE TO OBJECTS AND VARIABLES

TASKS HAVE THREE COSTS: SERIALIZATION AND DESERIALIZATION; I/O OR NETWORK COSTS, SINCE THE TASKS MUST BE SENT EVERY TIME IT IS EXECUTED; DELAY OF LAUNCH TIMES
SERIALIZING THINGS CAN BE COSTLY OR IMPOSSIBLE WITH THIRD-PARTY SOFTWARE

SLOW TASKS CAN BE RERUN (SPECULATIVE EXECUTION), BUT IS DISABLED BY DEFAULT IN SPARK
BY DEFAULT, SPARK WILL RETRY A FAILED TASK THREE TIMES, BEFORE FAILING A STAGE

SPARK USES FIRST-IN-FIRST-OUT-PRINCIPLE (FIFO), BUT THIS CAN BE CUSTOMIZED
POOLS CAN BE DEFINED, WHICH ARE SUBCLUSTERS (CLUSTER WITHIN THE CLUSTER), WITH OWN SCHEDULER; POSSIBLY FOR SOME USERS OR GROUPS
