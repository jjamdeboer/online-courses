C/C++ BACKEND, THEREFORE SLIGHTLY FASTER THAN PURE PYTHON CODE
USES, LIKE THEANO, DATA FLOW GRAPHS, WHERE DATA CAN BE IN TENSOR FORM, THUS THE NAME
HAS PYTHON AND C++ API, BUT PYTHON IS EASIER AND PREFERRED
TENSORFLOW HAS VERY FAST COMPILE TIMES AND SUPPORTS CPU'S, GPU'S AND DISTRIBUTED PROCESSING
BUILT-IN SUPPORT AND DOCUMENTATION FOR (DEEP) NEURAL NETWORKS; PREDEFINED FUNCTIONS THAT ARE USEFUL FOR NEURAL NETWORKS; FUTHERMORE IT HAS AUTO-DIFFERENTIATORS AND OPTIMIZERS

IN DATA FLOW GRAPHS THE NODES ARE THE MATHEMATICAL OPERATIONS AND THE EDGES ARE MULTI-DIMENSIONAL ARRAYS/TENSORS
STANDARD IS TO BUILD GRAPH AND THEN EXECUTE THIS GRAPH IN A SESSION
IN THIS GRAPH THERE ARE PLACEHOLDERS (WHERE DATA CAN BE USED AS INPUT), OTHER INPUT CAN BE VARIABLES, WHICH ARE DEFINED/CALCULATED WITHIN THE MODEL/GRAPH
PLACEHOLDERS NEED TO BE INITIALIZED (BEFORE ANY DATA IS FED INTO THE GRAPH)
AFTER INITIALIZING PLACEHOLDERS AND INTRODUCING VARIABLES, OPERATIONS NEED TO BE ADDED (MULTIPLICATION INPUT AND WEIGHTS/ADDING BIAS/...); THE GRAPH CAN BE EXECUTED DURING A SESSION, WHICH NEEDS TO BE CREATED

TENSORFLOW VARIABLES ARE USED TO SHARE AND PERSIST SOME NUMBERS. VARIABLES INITIALIZE AN OPERATION AND THIS OPERATION STORE A WRITABLE VALUE THAT PERSISTS BETWEEN SESSIONS; THUS UPDATING A VARIABLE IS POSSIBLE, WHEREAS UPDATE OF A TENSOR IS NOT POSSIBLE; VARIABLES MUST BE INITIIALIZED AFTER LAUNCHING THE GRAPH (DONE BY VARIABLE.global_variables_initializer())
FOR FEEDING EXTERNAL DATA INTO A GRAPH, USE PLACEHOLDERS (AT RUNTIME, USE tensorflow.Session().run(OPERATION ON PLACEHOLDER, feed_dict = {'PLACEHOLDER' = VALUE}))
OPERATIONS CAN BE FOUND AT: https://www.tensorflow.org/api_docs/python/tf#functions

DEEP LEARNING BECAME POPULAR DUE TO: INCREASED COMPUTING SPEED, INCREASING MEMORY CAPABILITIES, ADVANCES IN ALGORITHMS
DEEP NEURAL NETWORKS GENERALLY HAVE MORE THAN TWO LAYERS, EACH LAYER USES MATHEMATICAL MODELS FOR DATA PROCESSING, CAN BE USED FOR EXTRACTING FEATURES FROM DATA
CONVOLUTIONAL NEURAL NETWORKS (CNN): IMAGE RECOGNITION/IMAGE CLASSIFICATION/OBJECT RECOGNITION; AUTOMATIC FEATURE EXTRACTOR
RECURRENT NEURAL NETWORKS (RNN): SEQUENTIAL DATA/TIME SERIES/TEXT ANALYSIS -> SENTIMENT ANALYSIS/MACHINE TRANSLATION/SPEECH-TO-TEXT TRANSLATORS
RESTRICTED BOLTZMANN MACHINES (RBM): PATTERN DETECTION UNSUPERVISED, SHALLOW; SIMPLE AUTOENCODER; FEATURE EXTRACTOR/DIMENSIONALITY REDUCER/PATTERN RECOGNITION/RECOMMENDER SYSTEMS/FILLING DATA GAPS
DEEP BELIEF NETWORK (DBN): BUILT UP FROM RESTRICTED BOLTZMANN MACHINES, SOLVING VANISHING OR EXPLODING GRADIENT PROBLEM IN NEURAL NETWORKS; NEEDS ONLY SMALL DATASET, SINCE MOST OF THE WORK IS DONE UNSUPERVISED BY RESTRICTED BOLTZMANN MACHINES; CLASSIFIER/IMAGE RECOGNIZER/DISCRIMITIVE CLASSIFIER
AUTOENCODER: AUTOENCODER AND DECODER, SIMILAR TO DEEP BELIEF NETWORKS; FEATURE EXTRACTION/DIMENSIONALITY REDUCER/IMAGE RECOGNITION
