PARAMETERS THAT DETERMINE SPLIT CANDIDATE DECISIONS: CONTINUOUS FEATURES (FOR SMALL DATA SETS THE FEATURE IS ORDERED AND A DECISION IS DRAWN AT A SPECIFIC VALUE; FOR LARGE DATA SETS, ORDERING CAN BE COSTLY AND THE DATA IS SPLIT TO OTHER MACHINES AND THERE IT IS DONE LOCALLY), CATEGORICAL FEATURES, STOPPING RULES
MLLIB SUPPORTS BINARY CLASSIFICATION TREES, MULTI-CLASS CLASSIFICATION TREES, REGRESSION DECISION TREES
RECURSION STOPS WHEN: NODE DEPTH REACHES PREDEFINED PARAMETER; INFORMATION GAIN IS SMALLER THAN PREDEFINED PARAMETER; NUMBER OF INSTANCES ON A NODE ARE LESS THAN PREDEFINED PARAMETER

FOR TREES THREE PARAMETER TYPES: SPECIFIABLE PARAMETERS WITHOUT TUNING, TUNABLE PARAMETERS, STOPPING PARAMETERS (WHICH ARE ALSO TUNABLE)
- SPECIFIABLE PARAMETERS: NUMBER OF CLASSES; WHICH FEATURES ARE CATEGORICAL AND WHICH CATEGORIES THOSE CONTAIN
- TUNABLE PARAMETERS: SHOULD BE TUNED USING VALIDATION DATA SET; MAXIMUM NUMBER OF BINS WHEN TRANSFORMING A CONTINUOUS FEATURE INTO A CATEGORICAL ONE; IMPURITY MEASURES MIX OF CATEGORIES IN EACH NODE (FOR CLASSIFICATION GINI OR ENTROPY CAN BE BASED ON THIS, FOR REGRESSION VARIANCE CAN BE BASED ON THIS)
- STOPPING PARAMETERS (TUNABLE): NODE DEPTH REACHES PREDEFINED PARAMETER; INFORMATION GAIN IS SMALLER THAN PREDEFINED PARAMETER; NUMBER OF INSTANCES ON A NODE ARE LESS THAN PREDEFINED PARAMETER

FOR FOREST THE SAME PARAMETER TYPES, BUT WITH ADDITIONAL PARAMETERS:
- SPECIFIABLE PARAMETERS: SEED (RANDOM SEED THAT IS USED TO DETERMINE WHICH SUBSET OF THE FEATURES IS USED FOR EVERY TREE)
- TUNABLE PARAMETERS: NUMBER OF TREES (NUMBER OF TREES IN THE FOREST), FEATURE SUBSET STRATEGY (NUMBER OF FEATURES CONSIDERED FOR SPLITTING AT EACH NODE)
- STOPPING PARAMETERS (TUNABLE): MAXIMUM DEPTH (SAME PARAMETER, BUT DEEPER TREES ARE NOT AS BAD IN FOREST SINCE RESULTS ARE AVERAGED)
